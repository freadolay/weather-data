{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build a station list by using a bunch of IEM networks.\"\"\"\n",
    "stations = pd.DataFrame(columns=[\n",
    "    'station_id',\n",
    "    'station_name',\n",
    "    'state',\n",
    "    'country',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'elevation',\n",
    "    'climate_site',\n",
    "    'wfo',\n",
    "    'tzname',\n",
    "    'ncdc81',\n",
    "    'ncei91',\n",
    "    'ugc_county',\n",
    "    'ugc_zone',\n",
    "    'county',\n",
    "    'data_availability_range'\n",
    "])\n",
    "states = \"\"\"AK AL AR AZ CA CO CT DE FL GA HI IA ID IL IN KS KY LA MA MD ME\n",
    "    MI MN MO MS MT NC ND NE NH NJ NM NV NY OH OK OR PA RI SC SD TN TX UT VA VT\n",
    "    WA WI WV WY\"\"\"\n",
    "networks = []\n",
    "for state in states.split():\n",
    "    networks.append(f\"{state}_ASOS\")\n",
    "\n",
    "for network in networks:\n",
    "    if network not in ['MN_ASOS','WI_ASOS']:\n",
    "        continue\n",
    "    # Get metadata\n",
    "    uri = f\"https://mesonet.agron.iastate.edu/geojson/network/{network}.geojson\"\n",
    "    data = urlopen(uri)\n",
    "    jdict = json.load(data)\n",
    "    for site in jdict[\"features\"]:\n",
    "        new_site = {\n",
    "            'station_id': site['properties']['sid'],\n",
    "            'station_name': site['properties']['sname'],\n",
    "            'state': site['properties']['state'],\n",
    "            'country': site['properties']['country'],\n",
    "            'latitude': site['geometry']['coordinates'][1],\n",
    "            'longitude': site['geometry']['coordinates'][0],\n",
    "            'elevation': site['properties']['elevation'],\n",
    "            'climate_site': site['properties']['climate_site'],\n",
    "            'wfo': site['properties']['wfo'],\n",
    "            'tzname': site['properties']['tzname'],\n",
    "            'ncdc81': site['properties']['ncdc81'],\n",
    "            'ncei91': site['properties']['ncei91'],\n",
    "            'ugc_county': site['properties']['ugc_county'],\n",
    "            'ugc_zone': site['properties']['ugc_zone'],\n",
    "            'county': site['properties']['county'],\n",
    "            'data_availability_range': site['properties']['time_domain']\n",
    "        }\n",
    "        stations = stations.append(new_site, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>climate_site</th>\n",
       "      <th>wfo</th>\n",
       "      <th>tzname</th>\n",
       "      <th>ncdc81</th>\n",
       "      <th>ncei91</th>\n",
       "      <th>ugc_county</th>\n",
       "      <th>ugc_zone</th>\n",
       "      <th>county</th>\n",
       "      <th>data_availability_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>LSE</td>\n",
       "      <td>LA CROSSE</td>\n",
       "      <td>WI</td>\n",
       "      <td>US</td>\n",
       "      <td>43.88</td>\n",
       "      <td>-91.25</td>\n",
       "      <td>199.0</td>\n",
       "      <td>WI4370</td>\n",
       "      <td>ARX</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USW00014920</td>\n",
       "      <td>USW00014920</td>\n",
       "      <td>WIC063</td>\n",
       "      <td>WIZ041</td>\n",
       "      <td>La Crosse</td>\n",
       "      <td>(1948-Now)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id station_name state country  latitude  longitude  elevation  \\\n",
       "125        LSE    LA CROSSE    WI      US     43.88     -91.25      199.0   \n",
       "\n",
       "    climate_site  wfo           tzname       ncdc81       ncei91 ugc_county  \\\n",
       "125       WI4370  ARX  America/Chicago  USW00014920  USW00014920     WIC063   \n",
       "\n",
       "    ugc_zone     county data_availability_range  \n",
       "125   WIZ041  La Crosse              (1948-Now)  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[stations.station_name.str.contains('LA CROSSE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPTS = 6\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: LSE (2022-06-13 00:00:00 -> 2022-06-14 00:00:00)\n",
      "Downloading: LSE (2022-06-14 00:00:00 -> 2022-06-15 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "#### INPUTS ####\n",
    "start = datetime.datetime(2022, 6, 13)\n",
    "end = datetime.datetime(2022, 6, 15)\n",
    "stations_to_pull = ['LSE']\n",
    "\n",
    "# Define Time Interval (can only pull 24 hours at a time)\n",
    "interval = datetime.timedelta(hours=24)\n",
    "\n",
    "# Put the URI together to prep the data download\n",
    "df = None\n",
    "\n",
    "# Pull data for each station, 24 hours at a time\n",
    "for station_to_pull in stations_to_pull:\n",
    "    start_url = SERVICE + \"datda=all&tz=Etc/UTC&format=comma&latlon=yes&\"\n",
    "    start_url += f'station={station_to_pull}&'\n",
    "    now = start\n",
    "    while now < end:\n",
    "        now_url = start_url + start.strftime('year1=%Y&month1=%m&day1=%d&')\n",
    "        now_url += (now + interval).strftime('year2=%Y&month2=%m&day2=%d&')\n",
    "        print(f'Downloading: {station_to_pull} ({now} -> {(now+interval)})')\n",
    "        data = download_data(now_url)\n",
    "        str_io_data = StringIO(data[data.find('station'):])\n",
    "        df_data = pd.read_csv(str_io_data)\n",
    "        if df is None:\n",
    "            df = pd.DataFrame(columns=df_data.columns)\n",
    "        df = pd.concat([df, df_data], ignore_index=True)\n",
    "        now += interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
